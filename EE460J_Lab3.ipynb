{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EE460J_Lab3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjUAUYSgGCVs8DL4J2219B",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Causality-C/CHDL/blob/master/EE460J_Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNt36n6Aq4O-"
      },
      "source": [
        "# EE 460J Lab 3\n",
        "By:  Jeffrey Liu, Ryan Krogfoss, Johnathan Ghee,  \n",
        "\n",
        "Submission: Jeffrey Liu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3xNdci6cA1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bad831d1-02f3-4f8d-9a05-319b8f1ebe30"
      },
      "source": [
        "!pip install pdfminer"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for pdfminer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdfminer: filename=pdfminer-20191125-py3-none-any.whl size=6140100 sha256=a9810b6535b9cbfcbd9f3ec2258a6cbe69252e9377adbb4227e5ebf296a30d71\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/5e/f4/d210b46e9e4a28229ea070ed5b3efa92c3c29d1a7918dd4b97\n",
            "Successfully built pdfminer\n",
            "Installing collected packages: pycryptodome, pdfminer\n",
            "Successfully installed pdfminer-20191125 pycryptodome-3.10.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdF2qq5uWx7u"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import io\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfdocument import PDFDocument\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from pdfminer.pdfparser import PDFParser\n",
        "import re\n",
        "import os\n",
        "from urllib import request\n",
        "from google.colab import drive\n",
        "from math import log2, sqrt, ceil\n",
        "import random\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBq_WdFfrOxW"
      },
      "source": [
        "## Problem 1: A Bit of Informational Theory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXiB30zrrYbk"
      },
      "source": [
        "We can think about information as an average measure of entropy. Entropy can be mathematically defined as a weighted average of uncertainty conveyed by identifying the outcome of a random trial. More entropy corresponds to more information or randomness within a system. As with any measure of entropy, there is a relationship with probability. As a result, in systems that can be modeled as a random variable where the outcome is certain, there is no information because there is no randomness. Conversely, in systems where the outcome is perfectly random (when every outcome has an equal probability), there is a lot of uncertainty present. When dealing with conditional entropy, we can conclude that given random variables x and y, having more information about x can never increase the entropy of y (it’ll increase unless x and y are independent)\n",
        "\n",
        "Discrete source of information can be described mathematically by a stochastic process: a system which produces a sequence of symbols governed by a finite set of probabilities. There are many use cases for using discrete sources of information including understanding natural written language. By analyzing the frequency distribution of words (and their associated entropy), we can determine the average number of bits needed to encode a word. By empirical testing, i’ve found that the average bits needed for a word in the english language to be around 10.82 bits.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9Vk51atqrN8"
      },
      "source": [
        "## Problem 2: Scraping, Entropy, and ICML papers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLqiAUWUW2F0"
      },
      "source": [
        "# https://www.geeksforgeeks.org/how-to-scrape-all-pdf-files-in-a-website/\n",
        "url = 'http://proceedings.mlr.press/v70/'\n",
        "read = requests.get(url)\n",
        "content_html = read.content\n",
        "soup = BeautifulSoup(content_html, \"html.parser\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnJzLJtKROuS"
      },
      "source": [
        "a_tags = [link.get(\"href\") for link in soup.find_all('a')]\n",
        "pdfs = list(filter(lambda tag: tag[-3:] == 'pdf', a_tags))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6z2UYb7Q0rE"
      },
      "source": [
        "# Downloads all PDFs\n",
        "for pdf in pdfs:\n",
        "  response = requests.get(pdf)\n",
        "  if response.status_code == 200:\n",
        "    file_end = pdf.split(\"/\")[-1]\n",
        "    with open('pdfs/{}'.format(file_end), 'wb') as f:\n",
        "        f.write(response.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1mWdvdHa99j"
      },
      "source": [
        "freq = {}\n",
        "i = 0\n",
        "for pdf in pdfs:\n",
        "  pdf = pdf.split(\"/\")[-1]\n",
        "  # https://pdfminersix.readthedocs.io/en/latest/tutorial/composable.html\n",
        "  output_string = io.StringIO()\n",
        "  try:\n",
        "    with open(\"pdfs/{}\".format(pdf), \"rb\") as f:\n",
        "      parser = PDFParser(f)\n",
        "      doc = PDFDocument(parser)\n",
        "      rsrcmgr = PDFResourceManager()\n",
        "      device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
        "      interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "      for page in PDFPage.create_pages(doc):\n",
        "          interpreter.process_page(page)\n",
        "    file_str = output_string.getvalue()\n",
        "    r = file_str.replace(\"\\n\\n\",' ').replace('\\n',' ').replace(\"-\",'').replace(\",\",'').replace(\".\",'').replace('(','').replace(')','').lower().split(' ')\n",
        "    r = list(filter(lambda word: word.isalpha() and max([ord(word[i]) for i in range(len(word))]) < 123, r))\n",
        "    for word in r:\n",
        "      freq[word] = 1 if word not in freq else freq[word] + 1\n",
        "  except:\n",
        "    print(\"FIle Not Found\")\n",
        "  finally:\n",
        "    i += 1\n",
        "    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YblShe2ffoiE"
      },
      "source": [
        "# Get Frequencies Sorted\n",
        "freqs = [tuple(reversed(item)) for item in freq.items()]\n",
        "freqs.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRyJBxUlFTeH"
      },
      "source": [
        "# Save the frequencies\n",
        "textfile = open(\"word_file.txt\",'w')\n",
        "for element in freqs:\n",
        "  textfile.write(str(element[0]) + \",\" + element[1] + \"\\n\") \n",
        "textfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFhfq46pKBRa"
      },
      "source": [
        "# Calculate the Entropy of Words\n",
        "N = len(freqs)\n",
        "total = sum(freqs[i][0] for i in range(N))\n",
        "probs = [freqs[i][0]/total for i in range(N)]\n",
        "marginal_distr = [(probs[i],freqs[i][1]) for i in range(N)]\n",
        "entropy = -sum([ marginal_distr[i][0] * log2(marginal_distr[i][0]) for i in range(N)])\n",
        "marginal_distr\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_ds8F3Njgjx"
      },
      "source": [
        "# Random Variable for average and std of the number of words in an english sentence\n",
        "def give_sentence_stats():\n",
        "  o_string = io.StringIO()\n",
        "  \n",
        "  # Take one file to examine\n",
        "  with open(\"pdfs/alaa17a.pdf\".format(pdf), \"rb\") as f:\n",
        "    parser = PDFParser(f)\n",
        "    doc = PDFDocument(parser)\n",
        "    rsrcmgr = PDFResourceManager()\n",
        "    device = TextConverter(rsrcmgr, output_string, laparams=LAParams())\n",
        "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "    for page in PDFPage.create_pages(doc):\n",
        "      interpreter.process_page(page)\n",
        "  file_str = output_string.getvalue()\n",
        "  # Format to sentences\n",
        "  r = file_str.replace(\"\\n\\n\",' ').replace('\\n',' ').replace(\"-\",'').replace(\",\",'').replace('(','').replace(')','').lower().split('.')\n",
        "  r = list(filter(lambda x: x != \" \", r))\n",
        "  r = [s.strip() for s in r]\n",
        "  # Remove sentences with num words less than 3 (this is usually)\n",
        "  op = list(filter(lambda x: len(x.split(\" \")) > 3, r))\n",
        "  len_list = [len(x.split(' ')) for x in op]\n",
        "  mu, sigma = np.mean(len_list), sqrt(np.var(len_list))\n",
        "  return mu, sigma"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rprauZDxnl3s"
      },
      "source": [
        "# Function to pseudo-randomly generate N words \n",
        "# https://stackoverflow.com/questions/66513348/how-to-generate-pseudo-random-string-based-on-percentage-probability\n",
        "def generate_random_sentence(words, word_freq,sentence_len):\n",
        "  sentence = []\n",
        "\n",
        "  for i in range(sentence_len):\n",
        "    result = np.random.choice(words, p=word_freq)\n",
        "    sentence.append(result)\n",
        "\n",
        "  sentence[0] = sentence[0].capitalize()\n",
        "  sentence[-1] = sentence[-1] + \".\"\n",
        "  return \" \".join(sentence)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjZevoxyflgn",
        "outputId": "df545207-50a5-4ba7-da3c-38eb5ececc56"
      },
      "source": [
        "# Synthesize a random paragraph using the maginal distribution over words\n",
        "\n",
        "# Random Variable for Sentence Length\n",
        "mu, sigma = give_sentence_stats()\n",
        "\n",
        "# Lets say that there are 5 sentences in a paragraph\n",
        "num_sentences = 5\n",
        "words, word_freq = [tup[1] for tup in marginal_distr], [tup[0] for tup in marginal_distr]\n",
        "\n",
        "print(\"Generating Paragraph ... \\n\")\n",
        "for sentence in range(0,num_sentences):\n",
        "  sen_length = ceil(random.gauss(mu,sigma))\n",
        "  if sen_length >=3:\n",
        "    print(generate_random_sentence(words,word_freq,sen_length))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Paragraph ... \n",
            "\n",
            "Comparison part the of emmanuel three output al in least and and metropolis to al al stochastic markov last linear have second.\n",
            "As need with we can the in our the vaes we columns were and machines al admits s with matrices lower is.\n",
            "Linear and hu by dynamic to we of ex this sequential.\n",
            "Geometry where submodular per since games discrete et discuss hsieh xt.\n",
            "Allows jn of of which copyright mehdi linearly fast tion of et it one a density humans e copy and rt rankings but.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELzikbe5qT8e"
      },
      "source": [
        "# Extra Credit: Using n-gram model of words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "qVMz4rftOS-i",
        "outputId": "7aca9c1d-32ca-4400-8170-3b18606a39e3"
      },
      "source": [
        "## Lets see the # of words that occur X times\n",
        "trimmed = list(filter(lambda word: word[0] > 1, freqs))\n",
        "\n",
        "total = sum(trimmed[i][0] for i in range(len(trimmed)))\n",
        "probs = [freqs[i][0]/total for i in range(len(freqs))]\n",
        "times = [0 for i in range(20)] \n",
        "times_freq = times.copy()\n",
        "for pair in freqs:\n",
        "  if pair[0] < 20:\n",
        "    times_freq[pair[0]] += 1 \n",
        "times_freq\n",
        "size, scale = 1000, 10\n",
        "commutes = pd.Series(np.random.gamma(scale, size=size) ** 1.5)\n",
        "t = pd.Series({i: times_freq[i] for i in range(len(times_freq))})\n",
        "t.plot.bar(grid=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3dbea81fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsTf15evqvyy"
      },
      "source": [
        "## Problem 3: More on Kaggle Advanced Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2moneYO41KKw"
      },
      "source": [
        "1. https://www.kaggle.com/niteshx2/top-50-beginners-stacking-lgb-xgb is the best link I've found on the website. I've learned the importance of cleaning data and removing outliers as they will skew your model in an unfavorable direction. Additionally, the article touches upon feature engineering where one manually removes features that are intuitively not important and add improvements to the feature set (ie. Summing the squarefootage of all floors instead of having a separate squarefootage for each floor -> some houses do not have a 2nd floor). Finally, the article stresses the importance of stacking and ensambling different models to reduce overfitting. \n",
        "2. The best public leader board score I can achieve is 0.12156. I followed the code from the question 1 and implemented the changes to improve my rank to top 10% of submissions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCaYW3RGJlMo"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import skew\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV, ElasticNetCV\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.ensemble import StackingRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from scipy import stats\n",
        "from scipy.special import boxcox1p\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.svm import SVR\n",
        "from lightgbm import LGBMClassifier, LGBMRegressor\n",
        "from mlxtend.regressor import StackingCVRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtMHY6faMGig"
      },
      "source": [
        "# RMSE Function\n",
        "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "def rmsle(y, y_pred):\n",
        "    return np.sqrt(mean_squared_error(y, y_pred))\n",
        "\n",
        "def cv_rmse(model, X=X):\n",
        "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=kfolds))\n",
        "    return (rmse)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFMeDGiugV6G"
      },
      "source": [
        "def blend_models_predict(X):\n",
        "    return ((0.1 * elastic_model_full_data.predict(X)) + \\\n",
        "            (0.05 * lasso_model_full_data.predict(X)) + \\\n",
        "            (0.1 * ridge_model_full_data.predict(X)) + \\\n",
        "            (0.1 * svr_model_full_data.predict(X)) + \\\n",
        "            (0.1 * gbr_model_full_data.predict(X)) + \\\n",
        "            (0.15 * xgb_model_full_data.predict(X)) + \\\n",
        "            (0.1 * lgb_model_full_data.predict(X)) + \\\n",
        "            (0.3 * stack_gen_model.predict(np.array(X))))"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttxF_YkeMH-f"
      },
      "source": [
        "# Export Results of Y_Predict to CSV File\n",
        "def export_to_csv(y_pred):\n",
        "  df = pd.DataFrame({'Id' : [i + 1461 for i in range(X_sub.shape[0])], 'SalePrice': np.expm1(y_pred)})\n",
        "  df.to_csv('sample_submission.csv',index=False)"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8GC-nAtMJPG",
        "outputId": "2c54bb15-57ea-4a47-e10f-6e1adae820ac"
      },
      "source": [
        "# Read Data and Preprocess\n",
        "train = pd.read_csv(\"./input/train.csv\")\n",
        "test = pd.read_csv(\"./input/test.csv\")\n",
        "\n",
        "# Remove ID\n",
        "train.drop(['Id'], axis=1, inplace=True)\n",
        "test.drop(['Id'], axis=1, inplace=True)\n",
        "\n",
        "# Remove Outliers\n",
        "train = train[train.GrLivArea < 4500] # Outliers\n",
        "train.reset_index(drop=True, inplace=True)\n",
        "train['SalePrice'] = np.log1p(train['SalePrice'])\n",
        "y = train['SalePrice']\n",
        "\n",
        "train_features = train.drop(['SalePrice'], axis=1)\n",
        "test_features = test\n",
        "\n",
        "# We can use the drop parameter to avoid the old index being added as a column\n",
        "all_features = pd.concat([train_features,test_features]).reset_index(drop=True)\n",
        "\n",
        "# Features must have \n",
        "all_features['MSSubClass'] = all_features['MSSubClass'].apply(str)\n",
        "all_features['YrSold'] = all_features['YrSold'].astype(str)\n",
        "all_features['YrSold'] = all_features['YrSold'].astype(str)\n",
        "\n",
        "# Fill NA Columns with useful values\n",
        "all_features['Functional'] = all_features['Functional'].fillna('Typ') \n",
        "all_features['Electrical'] = all_features['Electrical'].fillna('SBrkr')\n",
        "all_features['KitchenQual'] = all_features['KitchenQual'].fillna(\"TA\") \n",
        "all_features[\"PoolQC\"] = all_features[\"PoolQC\"].fillna(\"None\")\n",
        "\n",
        "# Fill These columns with the most frequent value in the respective columns\n",
        "all_features['Exterior1st'] = all_features['Exterior1st'].fillna(all_features['Exterior1st'].mode()[0])\n",
        "all_features['Exterior2nd'] = all_features['Exterior2nd'].fillna(all_features['Exterior2nd'].mode()[0])\n",
        "all_features['SaleType'] = all_features['SaleType'].fillna(all_features['SaleType'].mode()[0])\n",
        "\n",
        "\n",
        "for col in ['GarageYrBlt', 'GarageArea', 'GarageCars']:\n",
        "  all_features[col] = all_features[col].fillna(0)\n",
        "\n",
        "for col in ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond']:\n",
        "  all_features[col] = all_features[col].fillna('None')\n",
        "\n",
        "for col in ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2']:\n",
        "    all_features[col] = all_features[col].fillna('None')\n",
        "\n",
        "# Fill missing values with the mode by each MSsubclass\n",
        "all_features['MSZoning'] = all_features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n",
        "\n",
        "# Update NaN object values with None\n",
        "objects = []\n",
        "for i in all_features.columns:\n",
        "    if all_features[i].dtype == object:\n",
        "        objects.append(i)\n",
        "all_features.update(all_features[objects].fillna('None'))\n",
        "\n",
        "# Update Numerical Cols NAN values with 0\n",
        "all_features['LotFrontage'] = all_features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
        "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
        "numerics = []\n",
        "for i in all_features.columns:\n",
        "    if all_features[i].dtype in numeric_dtypes:\n",
        "        numerics.append(i)\n",
        "all_features.update(all_features[numerics].fillna(0))\n",
        "\n",
        "numerics2 = []\n",
        "for i in all_features.columns:\n",
        "    if all_features[i].dtype in numeric_dtypes:\n",
        "        numerics2.append(i)\n",
        "skew_features = all_features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
        "high_skew = skew_features[skew_features > 0.5]\n",
        "skew_index = high_skew.index\n",
        "\n",
        "\n",
        "for i in skew_index:\n",
        "    all_features[i] = boxcox1p(all_features[i], stats.boxcox_normmax(all_features[i] + 1))\n",
        "\n",
        "len(train)\n"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:3538: PearsonRNearConstantInputWarning: An input array is nearly constant; the computed correlation coefficent may be inaccurate.\n",
            "  warnings.warn(PearsonRNearConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1458"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vz1NhnWZUvJ",
        "outputId": "5666a46d-3cfb-49d4-f67c-85ae4ef12022"
      },
      "source": [
        "# Feature Engineering\n",
        "\n",
        "# Drop Useless Features\n",
        "all_features = all_features.drop(['Utilities','Street','PoolQC'], axis=1)\n",
        "\n",
        "# Adding new features \n",
        "all_features['YrBltAndRemod']=all_features['YearBuilt']+all_features['YearRemodAdd']\n",
        "all_features['TotalSF']=all_features['TotalBsmtSF'] + all_features['1stFlrSF'] + all_features['2ndFlrSF']\n",
        "\n",
        "all_features['Total_sqr_footage'] = (all_features['BsmtFinSF1'] + all_features['BsmtFinSF2'] +\n",
        "                                 all_features['1stFlrSF'] + all_features['2ndFlrSF'])\n",
        "\n",
        "all_features['Total_Bathrooms'] = (all_features['FullBath'] + (0.5 * all_features['HalfBath']) +\n",
        "                               all_features['BsmtFullBath'] + (0.5 * all_features['BsmtHalfBath']))\n",
        "\n",
        "all_features['Total_porch_sf'] = (all_features['OpenPorchSF'] + all_features['3SsnPorch'] +\n",
        "                              all_features['EnclosedPorch'] + all_features['ScreenPorch'] +\n",
        "                              all_features['WoodDeckSF'])\n",
        "\n",
        "## For ex, if PoolArea = 0 , Then HasPool = 0 too\n",
        "\n",
        "all_features['haspool'] = all_features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\n",
        "all_features['has2ndfloor'] = all_features['2ndFlrSF'].apply(lambda x: 1 if x > 0 else 0)\n",
        "all_features['hasgarage'] = all_features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\n",
        "all_features['hasbsmt'] = all_features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\n",
        "all_features['hasfireplace'] = all_features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "final_features = pd.get_dummies(all_features).reset_index(drop=True)\n",
        "\n",
        "X = final_features.iloc[:len(y), :]\n",
        "X_sub = final_features.iloc[len(y):, :]\n",
        "X.shape, y.shape, X_sub.shape\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1458, 322), (1458,), (1459, 322))"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG_amhSpcHzI",
        "outputId": "88154139-acf7-48e9-aff4-21c1cb946b9a"
      },
      "source": [
        "outliers = [30,88,462,631,1322]\n",
        "X = X.drop(X.index[outliers])\n",
        "y = y.drop(y.index[outliers])\n",
        "\n",
        "\n",
        "# Determine Overfit by \n",
        "overfit = []\n",
        "for i in X.columns:\n",
        "    counts = X[i].value_counts()\n",
        "    zeros = counts.iloc[0]\n",
        "    if zeros / len(X) * 100 > 99.94:\n",
        "        overfit.append(i)\n",
        "\n",
        "overfit = list(overfit)\n",
        "X = X.drop(overfit, axis=1)\n",
        "X_sub = X_sub.drop(overfit, axis=1)\n",
        "X.shape, y.shape, X_sub.shape"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1453, 321), (1453,), (1459, 321))"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33-j_Wbkc2j9"
      },
      "source": [
        "alphas_alt = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\n",
        "alphas2 = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n",
        "e_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\n",
        "e_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO23ocRPdfZv"
      },
      "source": [
        "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=alphas_alt, cv=kfolds))\n",
        "lasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, alphas=alphas2, random_state=42, cv=kfolds))\n",
        "elasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, alphas=e_alphas, cv=kfolds, l1_ratio=e_l1ratio))                                \n",
        "svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003,))"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjxySsjseNqX"
      },
      "source": [
        "gbr = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, loss='huber', random_state =42)   "
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kISHgvDjef0J"
      },
      "source": [
        "lightgbm = LGBMRegressor(objective='regression', \n",
        "                                       num_leaves=4,\n",
        "                                       learning_rate=0.01, \n",
        "                                       n_estimators=5000,\n",
        "                                       max_bin=200, \n",
        "                                       bagging_fraction=0.75,\n",
        "                                       bagging_freq=5, \n",
        "                                       bagging_seed=7,\n",
        "                                       feature_fraction=0.2,\n",
        "                                       feature_fraction_seed=7,\n",
        "                                       verbose=-1,\n",
        "                                       )\n",
        "xgboost = XGBRegressor(learning_rate=0.01,n_estimators=3460,\n",
        "                                     max_depth=3, min_child_weight=0,\n",
        "                                     gamma=0, subsample=0.7,\n",
        "                                     colsample_bytree=0.7,\n",
        "                                     objective='reg:linear', nthread=-1,\n",
        "                                     scale_pos_weight=1, seed=27,\n",
        "                                     reg_alpha=0.00006)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elrC_NxqflPM"
      },
      "source": [
        "stack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, gbr, xgboost, lightgbm),\n",
        "                                meta_regressor=xgboost,\n",
        "                                use_features_in_secondary=True)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZALIUqdPgxsK",
        "outputId": "93feb66e-7fc5-48da-de4a-eff373ce500a"
      },
      "source": [
        "print('START Fit')\n",
        "\n",
        "print('stack_gen')\n",
        "stack_gen_model = stack_gen.fit(np.array(X), np.array(y))\n",
        "\n",
        "print('elasticnet')\n",
        "elastic_model_full_data = elasticnet.fit(X, y)\n",
        "\n",
        "print('Lasso')\n",
        "lasso_model_full_data = lasso.fit(X, y)\n",
        "\n",
        "print('Ridge')\n",
        "ridge_model_full_data = ridge.fit(X, y)\n",
        "\n",
        "print('Svr')\n",
        "svr_model_full_data = svr.fit(X, y)\n",
        "\n",
        "print('GradientBoosting')\n",
        "gbr_model_full_data = gbr.fit(X, y)\n",
        "\n",
        "print('xgboost')\n",
        "xgb_model_full_data = xgboost.fit(X, y)\n",
        "\n",
        "print('lightgbm')\n",
        "lgb_model_full_data = lightgbm.fit(X, y)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "START Fit\n",
            "stack_gen\n",
            "[01:18:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[01:18:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[01:18:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[01:19:04] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[01:19:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[01:19:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[01:20:39] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "elasticnet\n",
            "Lasso\n",
            "Ridge\n",
            "Svr\n",
            "GradientBoosting\n",
            "xgboost\n",
            "[01:21:27] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "lightgbm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j48t6C5EhFH_",
        "outputId": "3e2c4df4-b75f-4bc7-9e42-b2df6dd509b5"
      },
      "source": [
        "print('RMSLE score on train data:')\n",
        "print(rmsle(y, blend_models_predict(X)))\n",
        "y_pred = blend_models_predict(X_sub)\n",
        "export_to_csv(y_pred)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSLE score on train data:\n",
            "0.05581630574988134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ib_K1vioXHf"
      },
      "source": [
        "The RMSLE score on the train data is 0.055 but the actual submission score is 0.12156. Therefore, this model is an example of slight overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckUF479jpwLi",
        "outputId": "21c77d4a-3171-4176-99c0-a52d485e7dc7"
      },
      "source": [
        "model_lasso = LassoCV(alphas = [20,30,40]).fit(X, y)\n",
        "print(\"Underfit Model: {}\".format(rmsle(y, model_lasso.predict(X))))"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Underfit Model: 0.24420996740421833\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdORO-a7qKy-"
      },
      "source": [
        "# Score: 0.27546\n",
        "y_pred = model_lasso.predict(X_sub)\n",
        "np.expm1(y_pred)\n",
        "export_to_csv(y_pred)"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vlrlfp0rD3C"
      },
      "source": [
        "The RMSLE score on the train data is 0.24420996740421833 and the actual score is 0.27546. Both scores are very poor because of a high error rate and thus the model is underfitted."
      ]
    }
  ]
}